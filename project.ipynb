{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d15abf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed May 14 15:44:10 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 566.41                 Driver Version: 566.41         CUDA Version: 12.7     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                  Driver-Model | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce MX350         WDDM  |   00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   61C    P8             N/A / 5001W |     997MiB /   2048MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A     18628      C   ...ta\\Local\\Programs\\Ollama\\ollama.exe      N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3c64682",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain==0.1.14 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.1.14)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain==0.1.14) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain==0.1.14) (2.0.40)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain==0.1.14) (3.11.13)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain==0.1.14) (0.6.7)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain==0.1.14) (1.33)\n",
      "Requirement already satisfied: langchain-community<0.1,>=0.0.30 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain==0.1.14) (0.0.31)\n",
      "Requirement already satisfied: langchain-core<0.2.0,>=0.1.37 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain==0.1.14) (0.1.53)\n",
      "Requirement already satisfied: langchain-text-splitters<0.1,>=0.0.1 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain==0.1.14) (0.0.2)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain==0.1.14) (0.1.147)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain==0.1.14) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain==0.1.14) (2.11.4)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain==0.1.14) (2.32.3)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain==0.1.14) (8.5.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.14) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.14) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.14) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.14) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.14) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.14) (0.3.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.14) (1.18.3)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.1.14) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.1.14) (0.9.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain==0.1.14) (3.0.0)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.37->langchain==0.1.14) (23.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.1.14) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.1.14) (3.10.18)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.1.14) (1.0.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.1.14) (4.9.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.1.14) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.1.14) (1.0.8)\n",
      "Requirement already satisfied: idna in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.1.14) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.1.14) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3,>=1->langchain==0.1.14) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3,>=1->langchain==0.1.14) (2.33.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3,>=1->langchain==0.1.14) (4.12.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3,>=1->langchain==0.1.14) (0.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2->langchain==0.1.14) (3.4.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2->langchain==0.1.14) (2.2.3)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain==0.1.14) (3.2.2)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain==0.1.14) (1.1.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.1.14) (1.3.1)\n",
      "Requirement already satisfied: langchain-experimental==0.0.56 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.0.56)\n",
      "Requirement already satisfied: langchain<0.2.0,>=0.1.14 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-experimental==0.0.56) (0.1.14)\n",
      "Requirement already satisfied: langchain-core<0.2.0,>=0.1.37 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-experimental==0.0.56) (0.1.53)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain<0.2.0,>=0.1.14->langchain-experimental==0.0.56) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain<0.2.0,>=0.1.14->langchain-experimental==0.0.56) (2.0.40)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain<0.2.0,>=0.1.14->langchain-experimental==0.0.56) (3.11.13)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain<0.2.0,>=0.1.14->langchain-experimental==0.0.56) (0.6.7)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain<0.2.0,>=0.1.14->langchain-experimental==0.0.56) (1.33)\n",
      "Requirement already satisfied: langchain-community<0.1,>=0.0.30 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain<0.2.0,>=0.1.14->langchain-experimental==0.0.56) (0.0.31)\n",
      "Requirement already satisfied: langchain-text-splitters<0.1,>=0.0.1 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain<0.2.0,>=0.1.14->langchain-experimental==0.0.56) (0.0.2)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain<0.2.0,>=0.1.14->langchain-experimental==0.0.56) (0.1.147)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain<0.2.0,>=0.1.14->langchain-experimental==0.0.56) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain<0.2.0,>=0.1.14->langchain-experimental==0.0.56) (2.11.4)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain<0.2.0,>=0.1.14->langchain-experimental==0.0.56) (2.32.3)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain<0.2.0,>=0.1.14->langchain-experimental==0.0.56) (8.5.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.2.0,>=0.1.14->langchain-experimental==0.0.56) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.2.0,>=0.1.14->langchain-experimental==0.0.56) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.2.0,>=0.1.14->langchain-experimental==0.0.56) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.2.0,>=0.1.14->langchain-experimental==0.0.56) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.2.0,>=0.1.14->langchain-experimental==0.0.56) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.2.0,>=0.1.14->langchain-experimental==0.0.56) (0.3.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain<0.2.0,>=0.1.14->langchain-experimental==0.0.56) (1.18.3)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain<0.2.0,>=0.1.14->langchain-experimental==0.0.56) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain<0.2.0,>=0.1.14->langchain-experimental==0.0.56) (0.9.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain<0.2.0,>=0.1.14->langchain-experimental==0.0.56) (3.0.0)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.37->langchain-experimental==0.0.56) (23.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain<0.2.0,>=0.1.14->langchain-experimental==0.0.56) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain<0.2.0,>=0.1.14->langchain-experimental==0.0.56) (3.10.18)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain<0.2.0,>=0.1.14->langchain-experimental==0.0.56) (1.0.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain<0.2.0,>=0.1.14->langchain-experimental==0.0.56) (4.9.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain<0.2.0,>=0.1.14->langchain-experimental==0.0.56) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain<0.2.0,>=0.1.14->langchain-experimental==0.0.56) (1.0.8)\n",
      "Requirement already satisfied: idna in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain<0.2.0,>=0.1.14->langchain-experimental==0.0.56) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain<0.2.0,>=0.1.14->langchain-experimental==0.0.56) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3,>=1->langchain<0.2.0,>=0.1.14->langchain-experimental==0.0.56) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3,>=1->langchain<0.2.0,>=0.1.14->langchain-experimental==0.0.56) (2.33.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3,>=1->langchain<0.2.0,>=0.1.14->langchain-experimental==0.0.56) (4.12.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3,>=1->langchain<0.2.0,>=0.1.14->langchain-experimental==0.0.56) (0.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2->langchain<0.2.0,>=0.1.14->langchain-experimental==0.0.56) (3.4.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2->langchain<0.2.0,>=0.1.14->langchain-experimental==0.0.56) (2.2.3)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain<0.2.0,>=0.1.14->langchain-experimental==0.0.56) (3.2.2)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain<0.2.0,>=0.1.14->langchain-experimental==0.0.56) (1.1.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain<0.2.0,>=0.1.14->langchain-experimental==0.0.56) (1.3.1)\n",
      "Requirement already satisfied: langchain-community==0.0.31 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.0.31)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-community==0.0.31) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-community==0.0.31) (2.0.40)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-community==0.0.31) (3.11.13)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-community==0.0.31) (0.6.7)\n",
      "Requirement already satisfied: langchain-core<0.2.0,>=0.1.37 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-community==0.0.31) (0.1.53)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-community==0.0.31) (0.1.147)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-community==0.0.31) (1.26.4)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-community==0.0.31) (2.32.3)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-community==0.0.31) (8.5.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.0.31) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.0.31) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.0.31) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.0.31) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.0.31) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.0.31) (0.3.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.0.31) (1.18.3)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community==0.0.31) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community==0.0.31) (0.9.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.37->langchain-community==0.0.31) (1.33)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.37->langchain-community==0.0.31) (23.2)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.37->langchain-community==0.0.31) (2.11.4)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.37->langchain-community==0.0.31) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langsmith<0.2.0,>=0.1.0->langchain-community==0.0.31) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langsmith<0.2.0,>=0.1.0->langchain-community==0.0.31) (3.10.18)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langsmith<0.2.0,>=0.1.0->langchain-community==0.0.31) (1.0.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain-community==0.0.31) (4.9.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain-community==0.0.31) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain-community==0.0.31) (1.0.8)\n",
      "Requirement already satisfied: idna in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain-community==0.0.31) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain-community==0.0.31) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.37->langchain-community==0.0.31) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.37->langchain-community==0.0.31) (2.33.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.37->langchain-community==0.0.31) (4.12.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.37->langchain-community==0.0.31) (0.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2->langchain-community==0.0.31) (3.4.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2->langchain-community==0.0.31) (2.2.3)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain-community==0.0.31) (3.2.2)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community==0.0.31) (1.1.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain-community==0.0.31) (1.3.1)\n",
      "Requirement already satisfied: faiss-cpu==1.8.0 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.8.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from faiss-cpu==1.8.0) (1.26.4)\n",
      "Requirement already satisfied: pdfplumber==0.11.0 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.11.0)\n",
      "Requirement already satisfied: pdfminer.six==20231228 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pdfplumber==0.11.0) (20231228)\n",
      "Requirement already satisfied: Pillow>=9.1 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pdfplumber==0.11.0) (10.4.0)\n",
      "Requirement already satisfied: pypdfium2>=4.18.0 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pdfplumber==0.11.0) (4.30.1)\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pdfminer.six==20231228->pdfplumber==0.11.0) (3.4.0)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pdfminer.six==20231228->pdfplumber==0.11.0) (44.0.3)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber==0.11.0) (1.17.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber==0.11.0) (2.22)\n",
      "Collecting gradio==4.25.0\n",
      "  Using cached gradio-4.25.0-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: aiofiles<24.0,>=22.0 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio==4.25.0) (23.2.1)\n",
      "Requirement already satisfied: altair<6.0,>=4.2.0 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio==4.25.0) (5.5.0)\n",
      "Requirement already satisfied: fastapi in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio==4.25.0) (0.115.12)\n",
      "Requirement already satisfied: ffmpy in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio==4.25.0) (0.5.0)\n",
      "Collecting gradio-client==0.15.0 (from gradio==4.25.0)\n",
      "  Using cached gradio_client-0.15.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: httpx>=0.24.1 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio==4.25.0) (0.28.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.3 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio==4.25.0) (0.30.2)\n",
      "Requirement already satisfied: importlib-resources<7.0,>=1.3 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio==4.25.0) (6.5.2)\n",
      "Requirement already satisfied: jinja2<4.0 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio==4.25.0) (3.1.5)\n",
      "Requirement already satisfied: markupsafe~=2.0 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio==4.25.0) (2.1.5)\n",
      "Requirement already satisfied: matplotlib~=3.0 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio==4.25.0) (3.10.0)\n",
      "Requirement already satisfied: numpy~=1.0 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio==4.25.0) (1.26.4)\n",
      "Requirement already satisfied: orjson~=3.0 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio==4.25.0) (3.10.18)\n",
      "Requirement already satisfied: packaging in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio==4.25.0) (23.2)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio==4.25.0) (2.2.3)\n",
      "Requirement already satisfied: pillow<11.0,>=8.0 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio==4.25.0) (10.4.0)\n",
      "Requirement already satisfied: pydantic>=2.0 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio==4.25.0) (2.11.4)\n",
      "Requirement already satisfied: pydub in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio==4.25.0) (0.25.1)\n",
      "Requirement already satisfied: python-multipart>=0.0.9 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio==4.25.0) (0.0.20)\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.0 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio==4.25.0) (6.0.2)\n",
      "Requirement already satisfied: ruff>=0.2.2 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio==4.25.0) (0.11.9)\n",
      "Requirement already satisfied: semantic-version~=2.0 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio==4.25.0) (2.10.0)\n",
      "Requirement already satisfied: tomlkit==0.12.0 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio==4.25.0) (0.12.0)\n",
      "Requirement already satisfied: typer<1.0,>=0.9 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from typer[all]<1.0,>=0.9; sys_platform != \"emscripten\"->gradio==4.25.0) (0.15.3)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio==4.25.0) (4.12.2)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio==4.25.0) (0.34.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio-client==0.15.0->gradio==4.25.0) (2024.12.0)\n",
      "Requirement already satisfied: websockets<12.0,>=10.0 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio-client==0.15.0->gradio==4.25.0) (11.0.3)\n",
      "Requirement already satisfied: jsonschema>=3.0 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from altair<6.0,>=4.2.0->gradio==4.25.0) (4.23.0)\n",
      "Requirement already satisfied: narwhals>=1.14.2 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from altair<6.0,>=4.2.0->gradio==4.25.0) (1.38.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib~=3.0->gradio==4.25.0) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib~=3.0->gradio==4.25.0) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib~=3.0->gradio==4.25.0) (4.55.6)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib~=3.0->gradio==4.25.0) (1.4.8)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib~=3.0->gradio==4.25.0) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib~=3.0->gradio==4.25.0) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas<3.0,>=1.0->gradio==4.25.0) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas<3.0,>=1.0->gradio==4.25.0) (2025.1)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from typer<1.0,>=0.9->typer[all]<1.0,>=0.9; sys_platform != \"emscripten\"->gradio==4.25.0) (8.1.8)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from typer<1.0,>=0.9->typer[all]<1.0,>=0.9; sys_platform != \"emscripten\"->gradio==4.25.0) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from typer<1.0,>=0.9->typer[all]<1.0,>=0.9; sys_platform != \"emscripten\"->gradio==4.25.0) (14.0.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from click>=8.0.0->typer<1.0,>=0.9->typer[all]<1.0,>=0.9; sys_platform != \"emscripten\"->gradio==4.25.0) (0.4.6)\n",
      "Requirement already satisfied: anyio in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx>=0.24.1->gradio==4.25.0) (4.9.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx>=0.24.1->gradio==4.25.0) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx>=0.24.1->gradio==4.25.0) (1.0.8)\n",
      "Requirement already satisfied: idna in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx>=0.24.1->gradio==4.25.0) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpcore==1.*->httpx>=0.24.1->gradio==4.25.0) (0.14.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.19.3->gradio==4.25.0) (3.16.1)\n",
      "Requirement already satisfied: requests in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.19.3->gradio==4.25.0) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.19.3->gradio==4.25.0) (4.67.1)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==4.25.0) (25.1.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==4.25.0) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==4.25.0) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==4.25.0) (0.22.3)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic>=2.0->gradio==4.25.0) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic>=2.0->gradio==4.25.0) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic>=2.0->gradio==4.25.0) (0.4.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio==4.25.0) (1.17.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from rich>=10.11.0->typer<1.0,>=0.9->typer[all]<1.0,>=0.9; sys_platform != \"emscripten\"->gradio==4.25.0) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from rich>=10.11.0->typer<1.0,>=0.9->typer[all]<1.0,>=0.9; sys_platform != \"emscripten\"->gradio==4.25.0) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.9->typer[all]<1.0,>=0.9; sys_platform != \"emscripten\"->gradio==4.25.0) (0.1.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from anyio->httpx>=0.24.1->gradio==4.25.0) (1.3.1)\n",
      "Requirement already satisfied: starlette<0.47.0,>=0.40.0 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from fastapi->gradio==4.25.0) (0.46.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface-hub>=0.19.3->gradio==4.25.0) (3.4.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface-hub>=0.19.3->gradio==4.25.0) (2.2.3)\n",
      "Using cached gradio-4.25.0-py3-none-any.whl (17.1 MB)\n",
      "Using cached gradio_client-0.15.0-py3-none-any.whl (313 kB)\n",
      "Installing collected packages: gradio-client, gradio\n",
      "\n",
      "  Attempting uninstall: gradio-client\n",
      "\n",
      "    Found existing installation: gradio_client 1.10.0\n",
      "\n",
      "    Uninstalling gradio_client-1.10.0:\n",
      "\n",
      "      Successfully uninstalled gradio_client-1.10.0\n",
      "\n",
      "   ---------------------------------------- 0/2 [gradio-client]\n",
      "  Attempting uninstall: gradio\n",
      "   ---------------------------------------- 0/2 [gradio-client]\n",
      "    Found existing installation: gradio 5.29.0\n",
      "   ---------------------------------------- 0/2 [gradio-client]\n",
      "   -------------------- ------------------- 1/2 [gradio]\n",
      "   -------------------- ------------------- 1/2 [gradio]\n",
      "   -------------------- ------------------- 1/2 [gradio]\n",
      "   -------------------- ------------------- 1/2 [gradio]\n",
      "   -------------------- ------------------- 1/2 [gradio]\n",
      "   -------------------- ------------------- 1/2 [gradio]\n",
      "    Uninstalling gradio-5.29.0:\n",
      "   -------------------- ------------------- 1/2 [gradio]\n",
      "   -------------------- ------------------- 1/2 [gradio]\n",
      "   -------------------- ------------------- 1/2 [gradio]\n",
      "      Successfully uninstalled gradio-5.29.0\n",
      "   -------------------- ------------------- 1/2 [gradio]\n",
      "   -------------------- ------------------- 1/2 [gradio]\n",
      "   -------------------- ------------------- 1/2 [gradio]\n",
      "   -------------------- ------------------- 1/2 [gradio]\n",
      "   -------------------- ------------------- 1/2 [gradio]\n",
      "   -------------------- ------------------- 1/2 [gradio]\n",
      "   -------------------- ------------------- 1/2 [gradio]\n",
      "   -------------------- ------------------- 1/2 [gradio]\n",
      "   -------------------- ------------------- 1/2 [gradio]\n",
      "   -------------------- ------------------- 1/2 [gradio]\n",
      "   -------------------- ------------------- 1/2 [gradio]\n",
      "   -------------------- ------------------- 1/2 [gradio]\n",
      "   -------------------- ------------------- 1/2 [gradio]\n",
      "   -------------------- ------------------- 1/2 [gradio]\n",
      "   -------------------- ------------------- 1/2 [gradio]\n",
      "   -------------------- ------------------- 1/2 [gradio]\n",
      "   -------------------- ------------------- 1/2 [gradio]\n",
      "   -------------------- ------------------- 1/2 [gradio]\n",
      "   -------------------- ------------------- 1/2 [gradio]\n",
      "   -------------------- ------------------- 1/2 [gradio]\n",
      "   -------------------- ------------------- 1/2 [gradio]\n",
      "   -------------------- ------------------- 1/2 [gradio]\n",
      "   -------------------- ------------------- 1/2 [gradio]\n",
      "   -------------------- ------------------- 1/2 [gradio]\n",
      "   ---------------------------------------- 2/2 [gradio]\n",
      "\n",
      "Successfully installed gradio-4.25.0 gradio-client-0.15.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: typer 0.15.3 does not provide the extra 'all'\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain==0.1.14\n",
    "!pip install langchain-experimental==0.0.56\n",
    "!pip install langchain-community==0.0.31\n",
    "!pip install faiss-cpu==1.8.0\n",
    "!pip install pdfplumber==0.11.0\n",
    "!pip install gradio==4.25.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b859005",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠸ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠼ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠴ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠦ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠧ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠇ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠏ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠸ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠼ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠴ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠦ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest \u001b[K\n",
      "pulling 970aa74c0a90... 100% ▕████████████████▏ 274 MB                         \u001b[K\n",
      "pulling c71d239df917... 100% ▕████████████████▏  11 KB                         \u001b[K\n",
      "pulling ce4a164fc046... 100% ▕████████████████▏   17 B                         \u001b[K\n",
      "pulling 31df23ea7daa... 100% ▕████████████████▏  420 B                         \u001b[K\n",
      "verifying sha256 digest \u001b[K\n",
      "writing manifest \u001b[K\n",
      "success \u001b[K\u001b[?25h\u001b[?2026l\n"
     ]
    }
   ],
   "source": [
    "!ollama pull nomic-embed-text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80c0b592",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: serpapi in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.1.5)\n",
      "Requirement already satisfied: requests in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from serpapi) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->serpapi) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->serpapi) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->serpapi) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->serpapi) (2024.8.30)\n"
     ]
    }
   ],
   "source": [
    "!pip install serpapi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0cb49829",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.32.3)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (4.12.3)\n",
      "Requirement already satisfied: markdownify in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.1.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (4.67.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests) (2024.8.30)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from beautifulsoup4) (2.6)\n",
      "Requirement already satisfied: six<2,>=1.15 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from markdownify) (1.17.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install requests beautifulsoup4 markdownify tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7af9707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gradio in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (4.25.0)\n",
      "Collecting gradio\n",
      "  Using cached gradio-5.29.0-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: aiofiles<25.0,>=22.0 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (23.2.1)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (4.9.0)\n",
      "Requirement already satisfied: fastapi<1.0,>=0.115.2 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (0.115.12)\n",
      "Requirement already satisfied: ffmpy in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (0.5.0)\n",
      "Collecting gradio-client==1.10.0 (from gradio)\n",
      "  Using cached gradio_client-1.10.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: groovy~=0.1 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (0.1.2)\n",
      "Requirement already satisfied: httpx>=0.24.1 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (0.28.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.28.1 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (0.30.2)\n",
      "Requirement already satisfied: jinja2<4.0 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (3.1.5)\n",
      "Requirement already satisfied: markupsafe<4.0,>=2.0 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (2.1.5)\n",
      "Requirement already satisfied: numpy<3.0,>=1.0 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (1.26.4)\n",
      "Requirement already satisfied: orjson~=3.0 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (3.10.18)\n",
      "Requirement already satisfied: packaging in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (23.2)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (2.2.3)\n",
      "Requirement already satisfied: pillow<12.0,>=8.0 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (10.4.0)\n",
      "Requirement already satisfied: pydantic<2.12,>=2.0 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (2.11.4)\n",
      "Requirement already satisfied: pydub in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (0.25.1)\n",
      "Requirement already satisfied: python-multipart>=0.0.18 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (0.0.20)\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.0 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (6.0.2)\n",
      "Requirement already satisfied: ruff>=0.9.3 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (0.11.9)\n",
      "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (0.1.6)\n",
      "Requirement already satisfied: semantic-version~=2.0 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (2.10.0)\n",
      "Requirement already satisfied: starlette<1.0,>=0.40.0 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (0.46.2)\n",
      "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (0.12.0)\n",
      "Requirement already satisfied: typer<1.0,>=0.12 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (0.15.3)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (4.12.2)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (0.34.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio-client==1.10.0->gradio) (2024.12.0)\n",
      "Requirement already satisfied: websockets<16.0,>=10.0 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio-client==1.10.0->gradio) (11.0.3)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2025.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<2.12,>=2.0->gradio) (0.4.0)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (8.1.8)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (14.0.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from click>=8.0.0->typer<1.0,>=0.12->gradio) (0.4.6)\n",
      "Requirement already satisfied: certifi in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx>=0.24.1->gradio) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx>=0.24.1->gradio) (1.0.8)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.28.1->gradio) (3.16.1)\n",
      "Requirement already satisfied: requests in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.2.3)\n",
      "Using cached gradio-5.29.0-py3-none-any.whl (54.1 MB)\n",
      "Using cached gradio_client-1.10.0-py3-none-any.whl (322 kB)\n",
      "Installing collected packages: gradio-client, gradio\n",
      "\n",
      "  Attempting uninstall: gradio-client\n",
      "\n",
      "    Found existing installation: gradio_client 0.15.0\n",
      "\n",
      "    Uninstalling gradio_client-0.15.0:\n",
      "\n",
      "      Successfully uninstalled gradio_client-0.15.0\n",
      "\n",
      "   ---------------------------------------- 0/2 [gradio-client]\n",
      "  Attempting uninstall: gradio\n",
      "   ---------------------------------------- 0/2 [gradio-client]\n",
      "    Found existing installation: gradio 4.25.0\n",
      "   ---------------------------------------- 0/2 [gradio-client]\n",
      "    Uninstalling gradio-4.25.0:\n",
      "   ---------------------------------------- 0/2 [gradio-client]\n",
      "   -------------------- ------------------- 1/2 [gradio]\n",
      "   -------------------- ------------------- 1/2 [gradio]\n",
      "      Successfully uninstalled gradio-4.25.0\n",
      "   -------------------- ------------------- 1/2 [gradio]\n",
      "   -------------------- ------------------- 1/2 [gradio]\n",
      "   -------------------- ------------------- 1/2 [gradio]\n",
      "   -------------------- ------------------- 1/2 [gradio]\n",
      "   -------------------- ------------------- 1/2 [gradio]\n",
      "   -------------------- ------------------- 1/2 [gradio]\n",
      "   -------------------- ------------------- 1/2 [gradio]\n",
      "   -------------------- ------------------- 1/2 [gradio]\n",
      "   -------------------- ------------------- 1/2 [gradio]\n",
      "   -------------------- ------------------- 1/2 [gradio]\n",
      "   -------------------- ------------------- 1/2 [gradio]\n",
      "   -------------------- ------------------- 1/2 [gradio]\n",
      "   -------------------- ------------------- 1/2 [gradio]\n",
      "   -------------------- ------------------- 1/2 [gradio]\n",
      "   -------------------- ------------------- 1/2 [gradio]\n",
      "   -------------------- ------------------- 1/2 [gradio]\n",
      "   -------------------- ------------------- 1/2 [gradio]\n",
      "   -------------------- ------------------- 1/2 [gradio]\n",
      "   -------------------- ------------------- 1/2 [gradio]\n",
      "   -------------------- ------------------- 1/2 [gradio]\n",
      "   -------------------- ------------------- 1/2 [gradio]\n",
      "   -------------------- ------------------- 1/2 [gradio]\n",
      "   -------------------- ------------------- 1/2 [gradio]\n",
      "   -------------------- ------------------- 1/2 [gradio]\n",
      "   -------------------- ------------------- 1/2 [gradio]\n",
      "   -------------------- ------------------- 1/2 [gradio]\n",
      "   -------------------- ------------------- 1/2 [gradio]\n",
      "   -------------------- ------------------- 1/2 [gradio]\n",
      "   -------------------- ------------------- 1/2 [gradio]\n",
      "   -------------------- ------------------- 1/2 [gradio]\n",
      "   -------------------- ------------------- 1/2 [gradio]\n",
      "   -------------------- ------------------- 1/2 [gradio]\n",
      "   -------------------- ------------------- 1/2 [gradio]\n",
      "   -------------------- ------------------- 1/2 [gradio]\n",
      "   -------------------- ------------------- 1/2 [gradio]\n",
      "   -------------------- ------------------- 1/2 [gradio]\n",
      "   -------------------- ------------------- 1/2 [gradio]\n",
      "   -------------------- ------------------- 1/2 [gradio]\n",
      "   -------------------- ------------------- 1/2 [gradio]\n",
      "   -------------------- ------------------- 1/2 [gradio]\n",
      "   -------------------- ------------------- 1/2 [gradio]\n",
      "   -------------------- ------------------- 1/2 [gradio]\n",
      "   -------------------- ------------------- 1/2 [gradio]\n",
      "   -------------------- ------------------- 1/2 [gradio]\n",
      "   -------------------- ------------------- 1/2 [gradio]\n",
      "   ---------------------------------------- 2/2 [gradio]\n",
      "\n",
      "Successfully installed gradio-5.29.0 gradio-client-1.10.0\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade gradio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "468963f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-search-results in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.4.2)\n",
      "Requirement already satisfied: requests in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-search-results) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->google-search-results) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->google-search-results) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->google-search-results) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\radwa\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->google-search-results) (2024.8.30)\n"
     ]
    }
   ],
   "source": [
    "!pip install google-search-results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51028264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: google_search_results\n",
      "Version: 2.4.2\n",
      "Summary: Scrape and search localized results from Google, Bing, Baidu, Yahoo, Yandex, Ebay, Homedepot, youtube at scale using SerpApi.com\n",
      "Home-page: https://github.com/serpapi/google-search-results-python\n",
      "Author: vikoky\n",
      "Author-email: victor@serpapi.com\n",
      "License: MIT\n",
      "Location: C:\\Users\\Radwa\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\n",
      "Requires: requests\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip show google-search-results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "308c9759",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠸ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠼ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠴ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠦ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest \u001b[K\n",
      "pulling 6a0746a1ec1a... 100% ▕████████████████▏ 4.7 GB                         \u001b[K\n",
      "pulling 4fa551d4f938... 100% ▕████████████████▏  12 KB                         \u001b[K\n",
      "pulling 8ab4849b038c... 100% ▕████████████████▏  254 B                         \u001b[K\n",
      "pulling 577073ffcc6c... 100% ▕████████████████▏  110 B                         \u001b[K\n",
      "pulling 3f8eb4da87fa... 100% ▕████████████████▏  485 B                         \u001b[K\n",
      "verifying sha256 digest \u001b[K\n",
      "writing manifest \u001b[K\n",
      "success \u001b[K\u001b[?25h\u001b[?2026l\n"
     ]
    }
   ],
   "source": [
    "!ollama pull llama3:8b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "857b2731",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                       ID              SIZE      MODIFIED               \n",
      "llama3:8b                  365c0bd3c000    4.7 GB    Less than a second ago    \n",
      "nomic-embed-text:latest    0a109f422b47    274 MB    19 seconds ago            \n"
     ]
    }
   ],
   "source": [
    "!ollama list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "89d3d57f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.29.0\n"
     ]
    }
   ],
   "source": [
    "import gradio\n",
    "print(gradio.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "52e4c49d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading environment variables...\n",
      "Using Embedding Model: nomic-embed-text\n",
      "Using LLM Model: llama3:8b\n",
      "Document Directory: langchain_docs\n",
      "FAISS Index Path: faiss_langchain_docs_nomic-embed-text_index\n",
      "SERPAPI_API_KEY found.\n"
     ]
    }
   ],
   "source": [
    "# --- Imports ---\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import traceback\n",
    "import requests\n",
    "import markdownify\n",
    "import gradio as gr\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm.notebook import tqdm # Use notebook version of tqdm for better display\n",
    "from urllib.parse import urljoin, urlparse\n",
    "from dotenv import load_dotenv # For API keys\n",
    "\n",
    "# LangChain specific imports\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_community.llms import Ollama # Assuming Ollama LLM\n",
    "from langchain_community.document_loaders import DirectoryLoader, TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.agents import AgentType, initialize_agent \n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.tools import Tool\n",
    "from langchain_community.utilities import SerpAPIWrapper\n",
    "from langchain_experimental.tools import PythonREPLTool # Use experimental REPL tool\n",
    "\n",
    "# --- Configuration ---\n",
    "print(\"Loading environment variables...\")\n",
    "load_dotenv() # Load environment variables from .env file (if it exists)\n",
    "\n",
    "# Model Configuration\n",
    "EMBEDDING_MODEL = \"nomic-embed-text\" \n",
    "LLM_MODEL = \"llama3:8b\" \n",
    "print(f\"Using Embedding Model: {EMBEDDING_MODEL}\")\n",
    "print(f\"Using LLM Model: {LLM_MODEL}\")\n",
    "\n",
    "# Directory/Path Configuration\n",
    "DOCS_DIR = \"langchain_docs\"\n",
    "FAISS_INDEX_PATH = f\"faiss_{DOCS_DIR}_{EMBEDDING_MODEL.replace('/', '_').replace(':','_')}_index\" # Dynamic index path\n",
    "print(f\"Document Directory: {DOCS_DIR}\")\n",
    "print(f\"FAISS Index Path: {FAISS_INDEX_PATH}\")\n",
    "\n",
    "# API Key Configuration\n",
    "SERPAPI_API_KEY = os.getenv(\"SERPAPI_API_KEY\", \"e3a57f45c13ba53fa20085d04fe48db3ca8a597a260087dfc5cc60651808169e\")\n",
    "if SERPAPI_API_KEY :\n",
    "    print(\"SERPAPI_API_KEY found.\")\n",
    "else:\n",
    "    print(\"SERPAPI_API_KEY not found or is placeholder. Web Search tool will be disabled.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d4c83349",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting crawl from: https://python.langchain.com/docs/get_started/introduction\n",
      "Will stop after scraping a maximum of 100 pages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping documentation:   4%|▍         | 100/2588 [00:43<18:01,  2.30page/s, Scraped: 99/100, Queue: 2487, Visiting: https://python.langchain.com/v0.2/docs/how_to/docu...]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reached max 100 scraped pages during content extraction. Finalizing.\n",
      "\n",
      "✅ Scraper finished. Scraped content from 100 pages into 'langchain_docs'. Visited 101 URLs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin\n",
    "import markdownify\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import traceback\n",
    "from urllib.parse import urljoin, urlparse\n",
    "import re\n",
    "\n",
    "\n",
    "# --- Web Scraping Function ---\n",
    "def scrape_langchain_docs(output_dir=\"langchain_docs\"):\n",
    "    base_url = \"https://python.langchain.com\"\n",
    "    initial_seed_url = \"https://python.langchain.com/docs/get_started/introduction\"\n",
    "    max_pages_to_scrape = 100  # <<< SET YOUR LIMIT FOR QUICK TESTING\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    urls_to_visit = {initial_seed_url}\n",
    "    visited_urls = set()\n",
    "    scraped_content_urls = set()\n",
    "    session = requests.Session()\n",
    "    print(f\"Starting crawl from: {initial_seed_url}\")\n",
    "    print(f\"Will stop after scraping a maximum of {max_pages_to_scrape} pages.\")\n",
    "\n",
    "    with tqdm(desc=\"Scraping documentation\", unit=\"page\") as pbar:\n",
    "        while urls_to_visit:\n",
    "            if len(scraped_content_urls) >= max_pages_to_scrape: # Check before popping\n",
    "                print(f\"\\nReached max {max_pages_to_scrape} scraped pages. Finalizing.\")\n",
    "                break\n",
    "\n",
    "            current_url = urls_to_visit.pop()\n",
    "            if current_url in visited_urls:\n",
    "                continue\n",
    "            \n",
    "            pbar.set_postfix_str(f\"Scraped: {len(scraped_content_urls)}/{max_pages_to_scrape}, Queue: {len(urls_to_visit)}, Visiting: {current_url[:50]}...\")\n",
    "            visited_urls.add(current_url)\n",
    "\n",
    "            try:\n",
    "                response = session.get(current_url, timeout=15)\n",
    "                response.raise_for_status()\n",
    "                final_url = response.url\n",
    "\n",
    "                if final_url in scraped_content_urls or (final_url in visited_urls and final_url != current_url):\n",
    "                    if final_url != current_url: visited_urls.add(current_url)\n",
    "                    if final_url not in scraped_content_urls:\n",
    "                        soup_for_links = BeautifulSoup(response.text, 'html.parser')\n",
    "                    else:\n",
    "                        pbar.update(1)\n",
    "                        time.sleep(0.01) # Very short sleep for already processed\n",
    "                        continue\n",
    "\n",
    "                soup = BeautifulSoup(response.text, 'html.parser')\n",
    "                # ... (link discovery logic remains the same) ...\n",
    "                new_links_found = 0\n",
    "                for link_tag in soup.find_all('a', href=True):\n",
    "                    href = link_tag['href']\n",
    "                    next_url = urljoin(final_url, href)\n",
    "                    next_url_parsed = urlparse(next_url)\n",
    "                    next_url_no_fragment = next_url_parsed._replace(fragment=\"\").geturl()\n",
    "\n",
    "                    if next_url_no_fragment.startswith(base_url) and \\\n",
    "                       (\"docs\" in next_url_no_fragment or \"/latest/\" in next_url_no_fragment or re.search(r'/v\\d+\\.\\d+/', next_url_no_fragment)) and \\\n",
    "                       next_url_no_fragment not in visited_urls and \\\n",
    "                       next_url_no_fragment not in urls_to_visit and \\\n",
    "                       \"api.python.langchain.com\" not in next_url_no_fragment:\n",
    "                        urls_to_visit.add(next_url_no_fragment)\n",
    "                        new_links_found +=1\n",
    "\n",
    "\n",
    "                if final_url not in scraped_content_urls:\n",
    "                    main_content = (\n",
    "                        soup.find('article') or soup.find('main') or\n",
    "                        soup.find('div', role='main') or\n",
    "                        soup.find('div', class_='theme-doc-markdown markdown')\n",
    "                    )\n",
    "                    if main_content:\n",
    "                        md_content = markdownify.markdownify(str(main_content), heading_style=\"ATX\")\n",
    "                        if not md_content.strip():\n",
    "                            scraped_content_urls.add(final_url) \n",
    "                            pbar.update(1)\n",
    "                            time.sleep(0.01)\n",
    "                            continue\n",
    "\n",
    "                        url_path = urlparse(final_url).path\n",
    "                        name_parts = [part for part in url_path.split('/') if part]\n",
    "                        filename_base = \"_\".join(name_parts)\n",
    "                        if not filename_base: filename_base = \"root_doc_page\"\n",
    "                        filename = re.sub(r'[<>:\"/\\\\|?*]', '_', filename_base)[:2000] + \".md\"\n",
    "                        filepath = os.path.join(output_dir, filename)\n",
    "\n",
    "                        with open(filepath, 'w', encoding='utf-8') as f:\n",
    "                            f.write(f\"# Source: {final_url}\\n\\n\")\n",
    "                            f.write(md_content)\n",
    "                        scraped_content_urls.add(final_url) # Add to set *after* successful save\n",
    "\n",
    "                        if len(scraped_content_urls) >= max_pages_to_scrape: # Check again after scraping\n",
    "                            print(f\"\\nReached max {max_pages_to_scrape} scraped pages during content extraction. Finalizing.\")\n",
    "                            pbar.update(1) # Update for this last page\n",
    "                            break # Break from the while loop\n",
    "\n",
    "                pbar.update(1)\n",
    "                time.sleep(0.1) # Keep this for politeness during actual requests\n",
    "\n",
    "            except requests.exceptions.HTTPError as e:\n",
    "                pass # Or log to a file\n",
    "            except requests.exceptions.RequestException as e:\n",
    "                print(f\"Request error for {current_url}: {e}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Unexpected error processing {current_url}: {e}\")\n",
    "                traceback.print_exc()\n",
    "            \n",
    "            if len(urls_to_visit) == 0 and len(scraped_content_urls) < max_pages_to_scrape:\n",
    "                pbar.total = len(visited_urls) # Update total if queue is empty but limit not reached\n",
    "            elif len(scraped_content_urls) < max_pages_to_scrape :\n",
    "                 pbar.total = len(visited_urls) + len(urls_to_visit)\n",
    "            else: # Limit reached\n",
    "                pbar.total = len(visited_urls)\n",
    "\n",
    "\n",
    "    print(f\"\\n✅ Scraper finished. Scraped content from {len(scraped_content_urls)} pages into '{output_dir}'. Visited {len(visited_urls)} URLs.\")\n",
    "scrape_langchain_docs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c771d333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "safe_load_documents function defined.\n"
     ]
    }
   ],
   "source": [
    "DOCS_DIR=\"langchain_docs\"\n",
    "# Cell 3: Document Loading Function Definition\n",
    "def safe_load_documents(docs_path=DOCS_DIR):\n",
    "    \"\"\"Loads markdown documents safely from the specified directory.\"\"\"\n",
    "    print(f\"\\n--- Loading Documents ---\")\n",
    "    print(f\"Source Directory: {docs_path}\")\n",
    "    if not os.path.exists(docs_path) or not os.listdir(docs_path):\n",
    "        print(f\"WARNING: Directory '{docs_path}' is empty or does not exist. No documents to load.\")\n",
    "        return []\n",
    "\n",
    "    # Use TextLoader for basic Markdown loading\n",
    "    loader = DirectoryLoader(\n",
    "        docs_path,\n",
    "        glob=\"**/*.md\",\n",
    "        loader_cls=TextLoader,\n",
    "        loader_kwargs={'encoding': 'utf-8', 'autodetect_encoding': True},\n",
    "        show_progress=True,\n",
    "        use_multithreading=True,\n",
    "        silent_errors=True # Suppress errors during loading individual files\n",
    "    )\n",
    "\n",
    "    documents = []\n",
    "    print(f\"Attempting to load documents...\")\n",
    "    try:\n",
    "        # Use tqdm.notebook.tqdm for progress bar in notebook\n",
    "        loaded_items = loader.load() # Returns list of Document objects\n",
    "\n",
    "        if not loaded_items:\n",
    "            print(\"loader.load() returned empty list. No documents found or loaded.\")\n",
    "            return []\n",
    "\n",
    "        print(f\"loader.load() returned {len(loaded_items)} potential document(s). Validating...\")\n",
    "        invalid_count = 0\n",
    "        empty_count = 0\n",
    "        for i, doc in enumerate(loaded_items):\n",
    "            # Basic validation\n",
    "            if hasattr(doc, 'page_content') and hasattr(doc, 'metadata'):\n",
    "                if doc.page_content and doc.page_content.strip():\n",
    "                    # Extract source URL added by scraper\n",
    "                    source_match = re.match(r\"# Source: (https?://[^\\s]+)\", doc.page_content)\n",
    "                    if source_match:\n",
    "                         doc.metadata['source'] = source_match.group(1)\n",
    "                         doc.page_content = re.sub(r\"# Source: .*\\n\\n?\", \"\", doc.page_content, count=1) # Remove source line\n",
    "                    elif 'source' not in doc.metadata: # Fallback\n",
    "                        doc.metadata['source'] = doc.metadata.get('source', 'Unknown')\n",
    "\n",
    "                    documents.append(doc)\n",
    "                else:\n",
    "                    empty_count += 1\n",
    "            else:\n",
    "                 # print(f\"  WARNING: Item {i} (type: {type(doc)}) skipped - not valid Document structure.\") # Verbose\n",
    "                 invalid_count += 1\n",
    "\n",
    "        print(f\"Validation complete: Loaded {len(documents)} valid documents.\")\n",
    "        if empty_count > 0: print(f\"Skipped {empty_count} documents with empty content.\")\n",
    "        if invalid_count > 0: print(f\"Skipped {invalid_count} invalid items.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR during document loading process:\")\n",
    "        traceback.print_exc()\n",
    "        return [] # Return empty list on error\n",
    "\n",
    "    print(f\"--- Finished Loading Documents ({len(documents)} loaded) ---\")\n",
    "    return documents\n",
    "\n",
    "print(\"safe_load_documents function defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "905cfb95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setup_document_rag function defined.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define FAISS index path\n",
    "FAISS_INDEX_PATH = \"faiss_langchain_docs_nomic_index\"\n",
    "# Cell 4: RAG Setup Function Definition\n",
    "def setup_document_rag(docs_path=DOCS_DIR, index_path=FAISS_INDEX_PATH, embedding_service=None):\n",
    "    \"\"\"Sets up RAG using FAISS. Loads existing index or builds a new one.\"\"\"\n",
    "    print(f\"\\n--- Setting up Document RAG ---\")\n",
    "    print(f\"Document Source: {docs_path}\")\n",
    "    print(f\"FAISS Index Path: {index_path}\")\n",
    "\n",
    "    if not embedding_service:\n",
    "        print(\"ERROR: Embedding service (e.g., OllamaEmbeddings) is required for RAG setup.\")\n",
    "        return None\n",
    "\n",
    "    # Check if index exists and can be loaded\n",
    "    if os.path.exists(index_path):\n",
    "        try:\n",
    "            print(f\"Attempting to load existing FAISS index from: {index_path}\")\n",
    "            vectorstore = FAISS.load_local(index_path, embedding_service, allow_dangerous_deserialization=True)\n",
    "            print(\"FAISS index loaded successfully.\")\n",
    "            print(f\"--- Document RAG Setup Complete (Loaded Existing Index) ---\")\n",
    "            return vectorstore.as_retriever(search_kwargs={'k': 5}) # Return retriever, retrieve top 5\n",
    "        except Exception as e:\n",
    "            print(f\"WARNING: Could not load existing FAISS index (path: {index_path}): {e}. Will attempt to rebuild.\")\n",
    "           \n",
    "\n",
    "    # Build new index\n",
    "    print(\"Building new FAISS index...\")\n",
    "    documents = safe_load_documents(docs_path) # Load documents\n",
    "    if not documents:\n",
    "        print(\"ERROR: No valid documents loaded. Cannot build RAG index.\")\n",
    "        print(f\"--- Document RAG Setup Failed (No Documents) ---\")\n",
    "        return None\n",
    "\n",
    "    # Split documents\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1500, chunk_overlap=150) # Adjusted chunk size/overlap\n",
    "    try:\n",
    "        print(\"Splitting documents into chunks...\")\n",
    "        texts = text_splitter.split_documents(documents)\n",
    "        print(f\"Split {len(documents)} documents into {len(texts)} chunks.\")\n",
    "        if not texts:\n",
    "            print(\"ERROR: No text chunks generated after splitting. Cannot create vector store.\")\n",
    "            print(f\"--- Document RAG Setup Failed (No Chunks) ---\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR: Failed during document splitting:\")\n",
    "        traceback.print_exc()\n",
    "        print(f\"--- Document RAG Setup Failed (Splitting Error) ---\")\n",
    "        return None\n",
    "\n",
    "    # Create and save FAISS vector store\n",
    "    try:\n",
    "        print(f\"Creating FAISS vector store from {len(texts)} chunks using '{EMBEDDING_MODEL}'...\")\n",
    "        vectorstore = FAISS.from_documents(texts, embedding_service)\n",
    "        print(\"FAISS vector store created successfully.\")\n",
    "        print(f\"Saving FAISS index to: {index_path}\")\n",
    "        vectorstore.save_local(index_path)\n",
    "        print(\"FAISS index saved.\")\n",
    "        print(f\"--- Document RAG Setup Complete (Built New Index) ---\")\n",
    "        return vectorstore.as_retriever(search_kwargs={'k': 5}) # Return retriever, retrieve top 5\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR: Failed to create or save FAISS vector store:\")\n",
    "        traceback.print_exc()\n",
    "        print(f\"--- Document RAG Setup Failed (Vector Store Creation/Save Error) ---\")\n",
    "        return None\n",
    "\n",
    "print(\"setup_document_rag function defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1919c198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setup_tools function defined.\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Tools Setup Function Definition\n",
    "def setup_tools(retriever=None, serpapi_key=None):\n",
    "    \"\"\"Initializes and returns a list of agent tools with refined descriptions.\"\"\"\n",
    "    print(f\"\\n--- Setting up Agent Tools ---\")\n",
    "    local_tools = [] # Use a local list\n",
    "\n",
    "    # Tool 1: LangChain Document Search (RAG)\n",
    "    if retriever:\n",
    "        def doc_retriever_wrapper(query: str) -> str:\n",
    "            \"\"\"Searches the local LangChain documentation index.\"\"\"\n",
    "            print(f\"  [Tool Call] LangChain Document Search: '{query[:50]}...'\")\n",
    "            try:\n",
    "                docs = retriever.get_relevant_documents(query)\n",
    "                if not docs:\n",
    "                    print(\"    -> No relevant documents found.\")\n",
    "                    return \"No relevant documents found in the local LangChain knowledge base for this specific query. If the question is *not* specifically about LangChain implementation, consider using Web Search.\"\n",
    "                # Format the output\n",
    "                formatted_docs = []\n",
    "                for i, d in enumerate(docs):\n",
    "                    source = d.metadata.get('source', 'Unknown Source')\n",
    "                    content_preview = (d.page_content[:500] + '...') if len(d.page_content) > 500 else d.page_content\n",
    "                    formatted_docs.append(f\"Result {i+1}:\\nSource: {source}\\nContent Snippet:\\n{content_preview}\")\n",
    "                print(f\"    -> Found {len(docs)} relevant documents.\")\n",
    "                return \"Relevant excerpts from LangChain Documentation:\\n\\n---\\n\\n\".join(formatted_docs)\n",
    "            except Exception as e:\n",
    "                print(f\"    -> Error in doc_retriever_wrapper: {e}\")\n",
    "                # traceback.print_exc() # Uncomment for debug\n",
    "                return \"Error occurred while searching the local knowledge base.\"\n",
    "\n",
    "        local_tools.append(Tool(\n",
    "            name=\"LangChain Document Search\",\n",
    "            func=doc_retriever_wrapper,\n",
    "            description=(\n",
    "                \"Use this tool FIRST for questions specifically about LangChain features, concepts, implementation, classes, functions, or how-to examples (e.g., 'How to use LCEL?', 'What is LangGraph?', 'TextLoader example', 'Create a custom agent'). \"\n",
    "                \"Input should be a specific question about LangChain. This tool searches the indexed LangChain documentation. Only use other tools if this one explicitly finds nothing relevant for a LangChain-specific question.\"\n",
    "            )\n",
    "        ))\n",
    "        print(\"  Tool Added: LangChain Document Search\")\n",
    "    else:\n",
    "        print(\"  INFO: Document retriever not available. 'LangChain Document Search' tool skipped.\")\n",
    "\n",
    "    # Tool 2: Web Search (SerpAPI)\n",
    "    if serpapi_key :\n",
    "        try:\n",
    "            serpapi_search = SerpAPIWrapper(serpapi_api_key=serpapi_key)\n",
    "            def web_search_wrapper(query: str) -> str:\n",
    "                 \"\"\"Performs a web search using SerpAPI.\"\"\"\n",
    "                 print(f\"  [Tool Call] Web Search: '{query[:50]}...'\")\n",
    "                 try:\n",
    "                     result = serpapi_search.run(query)\n",
    "                     print(f\"    -> Web search result received.\")\n",
    "                     return result\n",
    "                 except Exception as e:\n",
    "                     print(f\"    -> Error during SerpAPI call: {e}\")\n",
    "                     return f\"Error during web search: {e}\"\n",
    "\n",
    "            local_tools.append(Tool(\n",
    "                name=\"Web Search\",\n",
    "                func=web_search_wrapper,\n",
    "                description=(\n",
    "                    \"Use this tool for general knowledge questions, current events, real-time information, or topics NOT specific to the LangChain library implementation *after* trying 'LangChain Document Search' if the query seemed LangChain related but yielded no results. \"\n",
    "                    \"Useful for questions about Python libraries other than LangChain, external services, or very recent developments. Input should be a concise search query.\"\n",
    "                )\n",
    "            ))\n",
    "            print(\"  Tool Added: Web Search (SerpAPI)\")\n",
    "        except ImportError:\n",
    "            print(\"  WARNING: 'google-search-results' package not installed. 'Web Search' tool unavailable. Install with: pip install google-search-results\")\n",
    "        except Exception as e:\n",
    "            print(f\"  WARNING: Failed to initialize SerpAPI tool: {e}. 'Web Search' tool unavailable.\")\n",
    "    elif not serpapi_key:\n",
    "        print(\"  INFO: SERPAPI_API_KEY not found. 'Web Search' tool unavailable.\")\n",
    "    else: # Key is the placeholder\n",
    "         print(f\"  INFO: SERPAPI_API_KEY is placeholder. 'Web Search' tool unavailable.\")\n",
    "\n",
    "    # Tool 3: Python REPL\n",
    "    try:\n",
    "        python_repl = PythonREPLTool()\n",
    "        def python_repl_wrapper(code: str) -> str:\n",
    "             \"\"\"Executes Python code using a REPL tool.\"\"\"\n",
    "             print(f\"  [Tool Call] Python REPL: '{code[:50]}...'\")\n",
    "             try:\n",
    "                 # Ensure input is treated as code, not description\n",
    "                 # The PythonREPLTool expects a string of Python code\n",
    "                 result = python_repl.run(code) # Pass code directly\n",
    "                 print(f\"    -> REPL execution finished.\")\n",
    "                 return result\n",
    "             except Exception as e:\n",
    "                 print(f\"    -> Error during Python REPL execution: {e}\")\n",
    "                 return f\"Error executing Python code: {e}\"\n",
    "\n",
    "        local_tools.append(Tool(\n",
    "            name=\"Python REPL\",\n",
    "            func=python_repl_wrapper,\n",
    "            description=(\n",
    "                \"Use this tool ONLY to execute specific, self-contained Python code snippets. Useful for calculations, simple standard library checks, or demonstrating basic Python syntax. \"\n",
    "                \"Input MUST be valid Python code (e.g., 'print(2+2)', 'import math; math.sqrt(16)'). Do NOT use it to ask questions, search the web, interact with LangChain objects (unless the code defines them fully), or run complex scripts. Avoid using if the task can be done by other tools.\"\n",
    "            )\n",
    "        ))\n",
    "        print(\"  Tool Added: Python REPL\")\n",
    "    except ImportError:\n",
    "         print(\"  WARNING: 'langchain_experimental' or 'python-repl' might not be installed. 'Python REPL' tool unavailable. Install with: pip install langchain_experimental\")\n",
    "    except Exception as e:\n",
    "        print(f\"  WARNING: Failed to initialize Python REPL tool: {e}. 'Python REPL' tool unavailable.\")\n",
    "\n",
    "    if not local_tools:\n",
    "        print(\"WARNING: No tools were successfully initialized!\")\n",
    "    else:\n",
    "        print(f\"Initialized Tools: {[tool.name for tool in local_tools]}\")\n",
    "    print(f\"--- Finished Setting up Agent Tools ---\")\n",
    "    return local_tools\n",
    "\n",
    "print(\"setup_tools function defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8bb3975a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialize_conversational_agent function defined.\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Agent Initialization Function Definition\n",
    "\n",
    "# IMPORT THE NEW MEMORY TYPE\n",
    "from langchain.memory import ConversationBufferMemory, ConversationTokenBufferMemory\n",
    "\n",
    "def initialize_conversational_agent(tools_list, agent_llm):\n",
    "    \"\"\"\n",
    "    Initializes and returns the conversational agent executor using the (deprecated)\n",
    "    initialize_agent function with CHAT_CONVERSATIONAL_REACT_DESCRIPTION.\n",
    "    Uses ConversationTokenBufferMemory to limit context size.\n",
    "    \"\"\"\n",
    "    print(f\"\\n--- Initializing Conversational Agent ---\")\n",
    "\n",
    "    if not agent_llm:\n",
    "        print(\"ERROR: LLM must be initialized before creating the agent.\")\n",
    "        print(f\"--- Agent Initialization Failed (No LLM) ---\")\n",
    "        return None\n",
    "    if not tools_list:\n",
    "        print(\"WARNING: No tools provided to the agent. It will rely solely on its internal knowledge and memory.\")\n",
    "\n",
    "    # Setup memory with token limiting\n",
    "    # Use a reasonable limit (e.g., 3500 tokens) for history to avoid exceeding LLM context\n",
    "    # Pass the llm to the memory for accurate token counting\n",
    "    MAX_MEMORY_TOKENS = 3500\n",
    "    print(f\"Initializing ConversationTokenBufferMemory (max_token_limit={MAX_MEMORY_TOKENS})...\")\n",
    "    try:\n",
    "        memory = ConversationTokenBufferMemory(\n",
    "            llm=agent_llm, # Pass LLM for token counting\n",
    "            memory_key=\"chat_history\",\n",
    "            return_messages=True,\n",
    "            output_key='output',\n",
    "            max_token_limit=MAX_MEMORY_TOKENS\n",
    "        )\n",
    "        print(\"Memory initialized.\")\n",
    "    except Exception as e:\n",
    "         print(f\"ERROR initializing ConversationTokenBufferMemory: {e}\")\n",
    "         print(\"Falling back to ConversationBufferMemory (may cause context length issues).\")\n",
    "         # Fallback (less ideal)\n",
    "         memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True, output_key='output')\n",
    "\n",
    "\n",
    "    try:\n",
    "        print(f\"Initializing agent with AgentType: {AgentType.CHAT_CONVERSATIONAL_REACT_DESCRIPTION} (using deprecated initialize_agent)\")\n",
    "        executor = initialize_agent(\n",
    "            tools=tools_list,\n",
    "            llm=agent_llm,\n",
    "            agent=AgentType.CHAT_CONVERSATIONAL_REACT_DESCRIPTION,\n",
    "            memory=memory, # Use the token buffer memory\n",
    "            verbose=True,\n",
    "            handle_parsing_errors=( # Provide specific guidance on parsing errors\n",
    "                \"Parsing Error: Ensure your output is either a valid JSON blob with 'action' and 'action_input' keys, \"\n",
    "                \"or the final answer prefixed with 'Final Answer:'. Check your thought process and generated output format carefully.\"\n",
    "            ),\n",
    "            max_iterations=13,\n",
    "            early_stopping_method=\"generate\",\n",
    "        )\n",
    "        print(\"Conversational agent initialized successfully.\")\n",
    "        print(f\"--- Agent Initialization Complete ---\")\n",
    "        return executor\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR: Failed to initialize conversational agent using initialize_agent.\")\n",
    "        print(f\"Error details: {e}\")\n",
    "        traceback.print_exc()\n",
    "        print(f\"--- Agent Initialization Failed ---\")\n",
    "        return None\n",
    "\n",
    "print(\"initialize_conversational_agent function defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2799d38e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setup_gradio_interface function defined.\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Gradio Interface Setup Function Definition\n",
    "def setup_gradio_interface(agent_executor_instance, agent_tools_list=None):\n",
    "    \"\"\"Sets up and returns the Gradio Blocks interface with a more user-friendly design.\"\"\"\n",
    "    print(f\"\\n--- Setting up Gradio Interface ---\")\n",
    "\n",
    "    if not agent_executor_instance:\n",
    "        print(\"ERROR: Agent executor instance is None. Cannot setup Gradio interface.\")\n",
    "        print(f\"--- Gradio Setup Failed ---\")\n",
    "        with gr.Blocks(theme=gr.themes.Default(primary_hue=gr.themes.colors.red), title=\"Chatbot Error\") as demo_error:\n",
    "            gr.Markdown(\"# Chatbot Initialization Error\\nThe agent executor could not be initialized. Please check the logs in the previous cells for errors (e.g., LLM/Tool setup failed).\")\n",
    "        return demo_error\n",
    "\n",
    "    failure_indicators = [\n",
    "        \"i cannot answer\", \"i can't answer\", \"i do not know\", \"i don't know\",\n",
    "        \"i don't have that information\", \"no relevant documents found\", \"i couldn't find any information\",\n",
    "        \"unable to find relevant information\", \"could not find information\", \"my knowledge is limited\",\n",
    "        \"the provided context does not contain\", \"i am unable to provide an answer\",\n",
    "        \"the search results do not provide\", \"i apologize, i cannot provide\", \"based on the search results\",\n",
    "        \"i'm sorry, but i couldn't find\", \"the document search did not return relevant results\",\n",
    "        \"the web search did not return relevant results\", \"no information found\", \"i'm afraid i can't\",\n",
    "        \"i am not able to provide\",\n",
    "    ]\n",
    "    failure_indicators += [f.replace(\"i \", \"i'm \") for f in failure_indicators if \"i \" in f]\n",
    "    failure_indicators += [f.replace(\"do not\", \"don't\") for f in failure_indicators if \"do not\" in f]\n",
    "    failure_indicators += [f.replace(\"can not\", \"can't\") for f in failure_indicators if \"can not\" in f]\n",
    "    failure_indicators = list(set(failure_indicators)) # Unique\n",
    "\n",
    "    default_empty_answer = \"I apologize, but I couldn't find a specific answer to your query using my available tools and knowledge at this time. Please try rephrasing or ask something else.\"\n",
    "\n",
    "    def respond(message: str, chat_history_pairs: list[list[str | None]] | None):\n",
    "        \"\"\"\n",
    "        Callback function for Gradio Blocks interface.\n",
    "        Handles user input, invokes the agent, and formats the response.\n",
    "        chat_history_pairs is a list of [user_msg, assistant_msg] pairs.\n",
    "        \"\"\"\n",
    "        print(f\"\\n[Gradio] User Input: '{message}'\")\n",
    "        current_history_for_logic = chat_history_pairs or [] # Use a local var for logic\n",
    "\n",
    "        if not message or message.strip() == \"\":\n",
    "            print(\"[Gradio] Empty input received.\")\n",
    "            # Return 3 values: empty textbox, unchanged history for chatbot, unchanged history for state\n",
    "            return \"\", current_history_for_logic, current_history_for_logic\n",
    "\n",
    "\n",
    "        final_response_text = default_empty_answer\n",
    "        try:\n",
    "            print(\"[Gradio] Invoking agent executor...\")\n",
    "            # Conversational Agent with ConversationBufferMemory handles history internally.\n",
    "            # We only provide the current user 'input'.\n",
    "            langchain_response = agent_executor_instance.invoke({\"input\": message})\n",
    "\n",
    "            response_text = langchain_response.get('output', \"\").strip() if isinstance(langchain_response, dict) else str(langchain_response).strip()\n",
    "            print(f\"[Gradio] Agent Raw Output (first 2000 chars): {response_text[:2000]}...\")\n",
    "\n",
    "            if not response_text:\n",
    "                print(\"[Gradio] Agent returned an empty response.\")\n",
    "                is_failure = True\n",
    "            else:\n",
    "                response_lower = response_text.lower()\n",
    "                is_failure = any(indicator in response_lower for indicator in failure_indicators)\n",
    "                if is_failure:\n",
    "                    # Check if the response is very short and contains a failure indicator\n",
    "                    if len(response_text) < 100 and any(indicator in response_lower for indicator in failure_indicators):\n",
    "                         print(f\"[Gradio] Detected clear failure indicator in a short response.\")\n",
    "                    else: # Could be a valid response that happens to contain an indicator substring\n",
    "                         is_failure = False # Re-evaluate, maybe it's not a true failure\n",
    "                         print(f\"[Gradio] Potential failure indicator found, but response is longer. Assuming valid unless empty.\")\n",
    "                         if not response_text.strip(): is_failure = True # Treat truly empty as failure\n",
    "\n",
    "            if not is_failure and response_text.strip(): # Ensure it's not a failure AND not just whitespace\n",
    "                final_response_text = response_text\n",
    "                print(\"[Gradio] Agent response seems valid.\")\n",
    "            else:\n",
    "                print(\"[Gradio] Agent response indicated failure, was empty, or was just whitespace. Using default failure message.\")\n",
    "                # final_response_text remains default_empty_answer\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[Gradio] ERROR during agent.invoke:\")\n",
    "            traceback.print_exc()\n",
    "            # Ensure final_response_text is always a string, even on error\n",
    "            final_response_text = f\"An error occurred during processing. Please check the notebook logs. Error type: {type(e).__name__}\"\n",
    "\n",
    "\n",
    "        # Append the new turn to the history that will be returned to Gradio\n",
    "        current_history_for_logic.append([message, final_response_text])\n",
    "        print(f\"[Gradio] Responding to UI...\")\n",
    "        # Return 3 values:\n",
    "        # 1. Empty string for the msg_textbox\n",
    "        # 2. The updated current_history for the chatbot_display\n",
    "        # 3. The updated current_history for the chat_history_state\n",
    "        return \"\", current_history_for_logic, current_history_for_logic\n",
    "\n",
    "    print(\"Setting up Gradio UI using gr.Blocks for more control...\")\n",
    "    # These globals are assumed to be defined in Cell 1\n",
    "    global LLM_MODEL, EMBEDDING_MODEL\n",
    "    tool_names = [t.name for t in agent_tools_list] if agent_tools_list else [\"None\"]\n",
    "    tools_str = ', '.join(tool_names)\n",
    "\n",
    "    custom_theme = gr.themes.Soft(\n",
    "        primary_hue=gr.themes.colors.blue,\n",
    "        secondary_hue=gr.themes.colors.sky,\n",
    "        neutral_hue=gr.themes.colors.slate, # Using slate for a slightly more modern neutral\n",
    "        font=[gr.themes.GoogleFont(\"Inter\"), \"ui-sans-serif\", \"system-ui\", \"sans-serif\"],\n",
    "    ).set(\n",
    "        body_background_fill=\"#f0f4f8\", # Light blue-gray background\n",
    "        block_background_fill=\"white\",\n",
    "        block_border_width=\"1px\",\n",
    "        block_shadow=\"*shadow_drop_lg\",\n",
    "        button_primary_background_fill=\"*primary_500\",\n",
    "        button_primary_background_fill_hover=\"*primary_600\",\n",
    "        button_primary_text_color=\"white\",\n",
    "        button_secondary_background_fill=\"*neutral_200\",\n",
    "        button_secondary_background_fill_hover=\"*neutral_300\",\n",
    "        button_secondary_text_color=\"*neutral_700\",\n",
    "    )\n",
    "\n",
    "    with gr.Blocks(theme=custom_theme, title=\"LangChain AI Assistant\", css=\".gradio-container {max-width: 800px !important; margin: auto !important;}\") as demo:\n",
    "        with gr.Row():\n",
    "           \n",
    "            gr.Markdown(\n",
    "                f\"\"\"\n",
    "                # LangChain AI Assistant\n",
    "                Ask questions about LangChain, general topics, or execute Python code.\n",
    "                \"\"\",\n",
    "                elem_id=\"app_title\" # For CSS styling if needed\n",
    "            )\n",
    "        with gr.Accordion(\"ℹ️ Assistant Details & Controls\", open=False):\n",
    "            gr.Markdown(\n",
    "                f\"\"\"\n",
    "                - **LLM:** `{LLM_MODEL}`\n",
    "                - **Embeddings:** `{EMBEDDING_MODEL}`\n",
    "                - **Available Tools:** `{tools_str}`\n",
    "                \"\"\",\n",
    "                elem_classes=\"details_markdown\" # For CSS styling if needed\n",
    "            )\n",
    "            clear_button = gr.Button(\"🗑️ Clear Chat History\", variant=\"secondary\", size=\"sm\")\n",
    "\n",
    "\n",
    "        chatbot_display = gr.Chatbot(\n",
    "            label=\"Conversation\",\n",
    "            height=500, # Slightly reduced height to accommodate header/footer\n",
    "            show_copy_button=True,\n",
    "            bubble_full_width=False,\n",
    "            render_markdown=True,\n",
    "            placeholder=\"Hi there! Ask me anything about LangChain or other topics.\",\n",
    "            elem_id=\"chatbot_display\"\n",
    "        )\n",
    "\n",
    "        chat_history_state = gr.State([]) # Manages the conversation history\n",
    "\n",
    "        with gr.Row(elem_id=\"input_area\"):\n",
    "            msg_textbox = gr.Textbox(\n",
    "                show_label=False,\n",
    "                placeholder=\"Type your message...\",\n",
    "                container=False,\n",
    "                lines=1, # Autogrows with input\n",
    "                # max_lines=5,\n",
    "                scale=7, # Textbox takes more space\n",
    "                elem_id=\"message_textbox\"\n",
    "            )\n",
    "            send_button = gr.Button(\"Send\", variant=\"primary\", scale=1, elem_id=\"send_button\")\n",
    "\n",
    "\n",
    "        submit_event_args = {\n",
    "            \"fn\": respond,\n",
    "            \"inputs\": [msg_textbox, chat_history_state],\n",
    "            \"outputs\": [msg_textbox, chatbot_display, chat_history_state],\n",
    "            \"api_name\": \"send_message\" # Optional: for API access\n",
    "        }\n",
    "\n",
    "        msg_textbox.submit(**submit_event_args)\n",
    "        send_button.click(**submit_event_args)\n",
    "\n",
    "        # Clear button functionality\n",
    "        def clear_chat_history_action():\n",
    "            print(\"[Gradio] Clearing chat history.\")\n",
    "            return \"\", [], [] # Clear textbox, chatbot display, and history state\n",
    "\n",
    "        clear_button.click(\n",
    "            clear_chat_history_action,\n",
    "            outputs=[msg_textbox, chatbot_display, chat_history_state],\n",
    "            # queue=False # Making clear immediate\n",
    "        )\n",
    "\n",
    "        gr.Examples(\n",
    "            examples=[\n",
    "                \"What is LangChain Expression Language (LCEL)?\",\n",
    "                \"How do I use a TextLoader to load documents?\",\n",
    "                \"Show me an example of a custom agent in LangChain.\",\n",
    "                \"What is the capital of France?\",\n",
    "                \"Calculate 2 to the power of 10\",\n",
    "                \"Who won the last FIFA world cup?\"\n",
    "            ],\n",
    "            inputs=[msg_textbox],\n",
    "            label=\"Quick Prompts ✨\",\n",
    "            cache_examples=False # No need to cache simple text inputs\n",
    "        )\n",
    "\n",
    "        gr.Markdown(\n",
    "            \"\"\"\n",
    "            <div style='text-align: center; font-size: 0.8em; color: #777; padding-top: 20px;'>\n",
    "            Powered by LangChain & Gradio.\n",
    "            </div>\n",
    "            \"\"\",\n",
    "            elem_id=\"footer_markdown\"\n",
    "        )\n",
    "\n",
    "    print(\"Gradio Blocks interface setup complete.\")\n",
    "    print(f\"--- Gradio Setup Complete ---\")\n",
    "    return demo\n",
    "\n",
    "print(\"setup_gradio_interface function defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f3ed87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting LangChain RAG Chatbot Application ---\n",
      "\n",
      "--- Initializing Models ---\n",
      "LLM Initialized: OK (llama3:8b)\n",
      "Embeddings Initialized: OK (nomic-embed-text)\n",
      "\n",
      "INFO: Found existing document directory: 'langchain_docs' with .md files. Skipping scraping.\n",
      "\n",
      "--- Setting up Document RAG ---\n",
      "Document Source: langchain_docs\n",
      "FAISS Index Path: faiss_langchain_docs_nomic_index\n",
      "Attempting to load existing FAISS index from: faiss_langchain_docs_nomic_index\n",
      "FAISS index loaded successfully.\n",
      "--- Document RAG Setup Complete (Loaded Existing Index) ---\n",
      "Document RAG setup check: Successful.\n",
      "\n",
      "--- Setting up Agent Tools ---\n",
      "  Tool Added: LangChain Document Search\n",
      "  Tool Added: Web Search (SerpAPI)\n",
      "  Tool Added: Python REPL\n",
      "Initialized Tools: ['LangChain Document Search', 'Web Search', 'Python REPL']\n",
      "--- Finished Setting up Agent Tools ---\n",
      "\n",
      "--- Initializing Conversational Agent ---\n",
      "Initializing ConversationTokenBufferMemory (max_token_limit=3500)...\n",
      "Memory initialized.\n",
      "Initializing agent with AgentType: AgentType.CHAT_CONVERSATIONAL_REACT_DESCRIPTION (using deprecated initialize_agent)\n",
      "Conversational agent initialized successfully.\n",
      "--- Agent Initialization Complete ---\n",
      "\n",
      "--- Setting up Gradio Interface ---\n",
      "Setting up Gradio UI using gr.Blocks for more control...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Radwa\\AppData\\Local\\Temp\\ipykernel_23208\\1915829423.py:139: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
      "  chatbot_display = gr.Chatbot(\n",
      "C:\\Users\\Radwa\\AppData\\Local\\Temp\\ipykernel_23208\\1915829423.py:139: DeprecationWarning: The 'bubble_full_width' parameter is deprecated and will be removed in a future version. This parameter no longer has any effect.\n",
      "  chatbot_display = gr.Chatbot(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradio Blocks interface setup complete.\n",
      "--- Gradio Setup Complete ---\n",
      "\n",
      "--- Launching Gradio App ---\n",
      "Attempting to launch Gradio on: http://127.0.0.1:7860\n",
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Application Setup and Launch Attempt Finished ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Gradio] User Input: 'who is the president of the USA?'\n",
      "[Gradio] Invoking agent executor...\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "    \"action\": \"Web Search\",\n",
      "    \"action_input\": \"Who is the current President of the United States?\"\n",
      "}\n",
      "```\n",
      "\n",
      "Please note that I've used the Web Search tool as the user's input doesn't seem to be related to LangChain features or concepts. If you'd like me to use a different tool, please let me know!\u001b[0m  [Tool Call] Web Search: 'Who is the current President of the United States?...'\n",
      "    -> Web search result received.\n",
      "\n",
      "Observation: \u001b[33;1m\u001b[1;3mDonald Trump\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mHere's the response:\n",
      "\n",
      "```json\n",
      "{\n",
      "    \"action\": \"Final Answer\",\n",
      "    \"action_input\": \"As of my knowledge cutoff, the President of the United States is Donald Trump.\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "[Gradio] Agent Raw Output (first 2000 chars): As of my knowledge cutoff, the President of the United States is Donald Trump....\n",
      "[Gradio] Agent response seems valid.\n",
      "[Gradio] Responding to UI...\n"
     ]
    }
   ],
   "source": [
    "DOCS_DIR = \"langchain_docs\"\n",
    "# Gradio Configuration\n",
    "GRADIO_SERVER_PORT = 7860\n",
    "GRADIO_SHARE = False\n",
    "# Cell 8: Main Application Execution Block\n",
    "\n",
    "print(\"--- Starting LangChain RAG Chatbot Application ---\")\n",
    "\n",
    "# --- Step 1: Initialize LLM and Embeddings ---\n",
    "print(\"\\n--- Initializing Models ---\")\n",
    "try:\n",
    "    # Make llm and embeddings global so functions in other cells can potentially use them\n",
    "    # Note: It's generally better to pass them as arguments, but following original structure\n",
    "    global llm, embeddings\n",
    "    llm = Ollama(model=LLM_MODEL, temperature = 0.1)\n",
    "    llm.invoke(\"Respond with just 'LLM OK'\") # Quick test\n",
    "    print(f\"LLM Initialized: OK ({LLM_MODEL})\")\n",
    "except Exception as e:\n",
    "    print(f\"ERROR: Failed to initialize Ollama LLM ({LLM_MODEL}): {e}\")\n",
    "    llm = None\n",
    "    traceback.print_exc()\n",
    "\n",
    "try:\n",
    "    embeddings = OllamaEmbeddings(model=EMBEDDING_MODEL)\n",
    "    embeddings.embed_query(\"Test embedding\") # Quick test\n",
    "    print(f\"Embeddings Initialized: OK ({EMBEDDING_MODEL})\")\n",
    "except Exception as e:\n",
    "    print(f\"ERROR: Failed to initialize Ollama Embeddings ({EMBEDDING_MODEL}): {e}\")\n",
    "    embeddings = None\n",
    "    traceback.print_exc()\n",
    "\n",
    "# Exit this cell's execution if core components failed\n",
    "if not llm or not embeddings:\n",
    "     print(\"\\nFATAL ERROR: Could not initialize LLM or Embeddings. Stopping execution.\")\n",
    "     # In a notebook, just stop here; no need for exit()\n",
    "     raise RuntimeError(\"LLM or Embeddings failed to initialize.\") # Raise error to stop cell execution\n",
    "\n",
    "# --- Step 2: Scrape Documents (Conditional) ---\n",
    "if not os.path.exists(DOCS_DIR) or not any(fname.endswith('.md') for fname in os.listdir(DOCS_DIR)):\n",
    "    print(f\"\\nINFO: '{DOCS_DIR}' directory not found or contains no .md files. Running web scraper...\")\n",
    "    try:\n",
    "         scrape_langchain_docs() # Uses defaults defined in Cell 1\n",
    "    except Exception as scrape_error:\n",
    "         print(f\"ERROR: Web scraping failed unexpectedly.\")\n",
    "         traceback.print_exc()\n",
    "         print(\"WARNING: Proceeding without newly scraped documents due to scraper error.\")\n",
    "else:\n",
    "    print(f\"\\nINFO: Found existing document directory: '{DOCS_DIR}' with .md files. Skipping scraping.\")\n",
    "\n",
    "# --- Step 3: Setup Document Retriever (RAG) ---\n",
    "# Requires embeddings service from Step 1\n",
    "rag_retriever = None # Ensure it's reset if RAG setup fails\n",
    "if embeddings: # Only proceed if embeddings initialized\n",
    "    rag_retriever = setup_document_rag(embedding_service=embeddings) # Calls function from Cell 4\n",
    "    if rag_retriever:\n",
    "        print(\"Document RAG setup check: Successful.\")\n",
    "    else:\n",
    "        print(\"Document RAG setup check: Failed or no documents found. Proceeding without RAG tool.\")\n",
    "else:\n",
    "    print(\"Skipping RAG setup because embeddings failed to initialize.\")\n",
    "\n",
    "\n",
    "# --- Step 4: Setup Agent Tools ---\n",
    "# Requires rag_retriever (optional) from Step 3\n",
    "agent_tools = [] # Ensure it's reset\n",
    "agent_tools = setup_tools(retriever=rag_retriever, serpapi_key=SERPAPI_API_KEY) # Calls function from Cell 5\n",
    "if not agent_tools:\n",
    "     print(\"WARNING: No agent tools were configured. Agent capabilities will be limited.\")\n",
    "\n",
    "# --- Step 5: Initialize Conversational Agent ---\n",
    "# Requires llm from Step 1 and agent_tools from Step 4\n",
    "agent_executor = None # Ensure it's reset\n",
    "if llm: # Only proceed if LLM initialized\n",
    "    agent_executor = initialize_conversational_agent(tools_list=agent_tools, agent_llm=llm) # Calls function from Cell 6\n",
    "    if not agent_executor:\n",
    "         print(\"ERROR: Failed to initialize the conversational agent. UI will show an error message.\")\n",
    "else:\n",
    "    print(\"Skipping agent initialization because LLM failed to initialize.\")\n",
    "\n",
    "# --- Step 6: Setup Gradio Interface ---\n",
    "# Requires agent_executor from Step 5\n",
    "gradio_app = setup_gradio_interface(agent_executor, agent_tools_list=agent_tools) # Calls function from Cell 7\n",
    "\n",
    "# --- Step 7: Launch Gradio Application ---\n",
    "if gradio_app:\n",
    "    print(\"\\n--- Launching Gradio App ---\")\n",
    "    try:\n",
    "        print(f\"Attempting to launch Gradio on: http://127.0.0.1:{GRADIO_SERVER_PORT}\")\n",
    "        # Launch in a way that works well in notebooks (inline or new tab)\n",
    "        # share=True generates a public link (requires Gradio account/tunneling)\n",
    "        gradio_app.launch(\n",
    "            server_name=\"127.0.0.1\",\n",
    "            server_port=GRADIO_SERVER_PORT,\n",
    "            share=GRADIO_SHARE,\n",
    "            # In a notebook, you might not need blocking, but launch() usually handles this.\n",
    "            # prevent_thread_lock=True, # May help in some notebook environments\n",
    "        )\n",
    "        # Note: In some notebook setups, you might need to manually stop the kernel\n",
    "        # to fully shut down the Gradio server after you're done.\n",
    "    except OSError as oe:\n",
    "        if \"address already in use\" in str(oe).lower() or \"cannot find empty port\" in str(oe).lower():\n",
    "             print(f\"\\n*** GRADIO ERROR: Port {GRADIO_SERVER_PORT} is already in use! ***\")\n",
    "             print(f\"Stop any other running Gradio apps or change GRADIO_SERVER_PORT in Cell 1.\")\n",
    "        else:\n",
    "             print(f\"ERROR: Failed to launch Gradio app due to an OS Error:\")\n",
    "             traceback.print_exc()\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR: Failed to launch Gradio app:\")\n",
    "        traceback.print_exc()\n",
    "else:\n",
    "    print(\"\\n--- Gradio App Launch Skipped ---\")\n",
    "    print(\"Gradio app could not be launched because the UI setup failed (likely due to agent initialization failure). Check previous logs.\")\n",
    "\n",
    "print(\"\\n--- Application Setup and Launch Attempt Finished ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5378ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07732e2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
